{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# For saving dictionaries\n",
    "import pickle\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For neural networks\n",
    "import torch\n",
    "\n",
    "# Computation of asset metrics\n",
    "from portfolio_stats import PortfolioStats\n",
    "\n",
    "# Time series splitting for walk forward modeling\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# Neural network portfolio optimizer and objective functions\n",
    "from workflow.tools.no_leverage_models import LSTMPortOpt_NL, CNNPortOpt_NL, FCNPortOpt_NL\n",
    "from workflow.tools.metrics import neg_sharpe_ratio\n",
    "\n",
    "# Tensor transform\n",
    "from workflow.tools.conversion import to_tensors\n",
    "\n",
    "from workflow.tools.utils import set_plot_style, strftime\n",
    "\n",
    "set_plot_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BONDS</th>\n",
       "      <th>COMMODITIES</th>\n",
       "      <th>STOCKS</th>\n",
       "      <th>VOLATILIITY</th>\n",
       "      <th>BONDS_RET</th>\n",
       "      <th>COMMODITIES_RET</th>\n",
       "      <th>STOCKS_RET</th>\n",
       "      <th>VOLATILIITY_RET</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-02-07</th>\n",
       "      <td>58.516796</td>\n",
       "      <td>21.282080</td>\n",
       "      <td>44.861336</td>\n",
       "      <td>13.59</td>\n",
       "      <td>-0.000699</td>\n",
       "      <td>-0.029352</td>\n",
       "      <td>-0.009784</td>\n",
       "      <td>0.041313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-02-08</th>\n",
       "      <td>58.487652</td>\n",
       "      <td>21.191517</td>\n",
       "      <td>45.184078</td>\n",
       "      <td>12.83</td>\n",
       "      <td>-0.000498</td>\n",
       "      <td>-0.004264</td>\n",
       "      <td>0.007168</td>\n",
       "      <td>-0.057548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-02-09</th>\n",
       "      <td>58.522652</td>\n",
       "      <td>21.390755</td>\n",
       "      <td>45.098019</td>\n",
       "      <td>13.12</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.009358</td>\n",
       "      <td>-0.001906</td>\n",
       "      <td>0.022352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-02-10</th>\n",
       "      <td>58.399944</td>\n",
       "      <td>21.001339</td>\n",
       "      <td>45.191254</td>\n",
       "      <td>12.87</td>\n",
       "      <td>-0.002099</td>\n",
       "      <td>-0.018373</td>\n",
       "      <td>0.002065</td>\n",
       "      <td>-0.019239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-02-13</th>\n",
       "      <td>58.440830</td>\n",
       "      <td>20.675316</td>\n",
       "      <td>44.986858</td>\n",
       "      <td>13.35</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>-0.015646</td>\n",
       "      <td>-0.004533</td>\n",
       "      <td>0.036617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                BONDS  COMMODITIES     STOCKS  VOLATILIITY  BONDS_RET  \\\n",
       "Date                                                                    \n",
       "2006-02-07  58.516796    21.282080  44.861336        13.59  -0.000699   \n",
       "2006-02-08  58.487652    21.191517  45.184078        12.83  -0.000498   \n",
       "2006-02-09  58.522652    21.390755  45.098019        13.12   0.000598   \n",
       "2006-02-10  58.399944    21.001339  45.191254        12.87  -0.002099   \n",
       "2006-02-13  58.440830    20.675316  44.986858        13.35   0.000700   \n",
       "\n",
       "            COMMODITIES_RET  STOCKS_RET  VOLATILIITY_RET  \n",
       "Date                                                      \n",
       "2006-02-07        -0.029352   -0.009784         0.041313  \n",
       "2006-02-08        -0.004264    0.007168        -0.057548  \n",
       "2006-02-09         0.009358   -0.001906         0.022352  \n",
       "2006-02-10        -0.018373    0.002065        -0.019239  \n",
       "2006-02-13        -0.015646   -0.004533         0.036617  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "kwargs = {\n",
    "    \"index_col\": 0,\n",
    "    \"parse_dates\": True\n",
    "}\n",
    "\n",
    "features = pd.read_csv(\"workflow/data/features.csv\", **kwargs)\n",
    "\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4403, 50, 8), (4403, 4))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define lookback window\n",
    "lookback = 50\n",
    "n_samples = len(features) - lookback\n",
    "n_features = len(features.columns)\n",
    "\n",
    "# Get columns related to returns, and index names\n",
    "return_cols = [col for col in features.columns if \"RET\" in col]\n",
    "indices = features.columns[~features.columns.isin(return_cols)]\n",
    "\n",
    "# Initialize input data with zeros\n",
    "X_ = np.zeros((n_samples, lookback, n_features))\n",
    "\n",
    "# Extract target values starting from the lookback index\n",
    "y = features[return_cols].iloc[lookback:].values\n",
    "\n",
    "# Populate the 'X' tensor using a rolling window of size 'lookback'\n",
    "for i in range(lookback, len(features)):\n",
    "    X_[i-lookback] = features.iloc[i-lookback:i]\n",
    "\n",
    "X_.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: FCN ---\n",
      "Split 1 (02/07/2006 - 07/31/2013): Epoch 100/100 (100.00%) | T: 0.95816 V: 0.20811\n",
      "Split 2 (02/07/2006 - 07/31/2015): Epoch 100/100 (100.00%) | T: 0.85916 V: 0.19985\n",
      "Split 3 (02/07/2006 - 08/01/2017): Epoch 100/100 (100.00%) | T: -0.16818 V: 0.24597\n",
      "Split 4 (02/07/2006 - 08/02/2019): Epoch 100/100 (100.00%) | T: 0.36449 V: 0.54555\n",
      "Split 5 (02/07/2006 - 08/03/2021): Epoch 100/100 (100.00%) | T: 0.44266 V: 0.41388\n",
      "\n",
      "Test Period: 10/14/2013 - 10/16/2023 (10.01 years)\n",
      "\n",
      "2: CNN ---\n",
      "Split 1 (02/07/2006 - 07/31/2013): Epoch 100/100 (100.00%) | T: 0.08220 V: -0.01064\n",
      "Split 2 (02/07/2006 - 07/31/2015): Epoch 100/100 (100.00%) | T: 0.45351 V: 0.56373\n",
      "Split 3 (02/07/2006 - 08/01/2017): Epoch 100/100 (100.00%) | T: 0.85160 V: 0.11811\n",
      "Split 4 (02/07/2006 - 08/02/2019): Epoch 100/100 (100.00%) | T: 0.82607 V: 0.04248\n",
      "Split 5 (02/07/2006 - 08/03/2021): Epoch 100/100 (100.00%) | T: 1.51045 V: -0.03195\n",
      "\n",
      "Test Period: 10/14/2013 - 10/16/2023 (10.01 years)\n",
      "\n",
      "3: LSTM ---\n",
      "Split 1 (02/07/2006 - 07/31/2013): Epoch 100/100 (100.00%) | T: 2.89951 V: 0.96545\n",
      "Split 2 (02/07/2006 - 07/31/2015): Epoch 100/100 (100.00%) | T: 2.93712 V: 0.96269\n",
      "Split 3 (02/07/2006 - 08/01/2017): Epoch 100/100 (100.00%) | T: 2.71699 V: 1.20310\n",
      "Split 4 (02/07/2006 - 08/02/2019): Epoch 100/100 (100.00%) | T: 3.06352 V: 1.01863\n",
      "Split 5 (02/07/2006 - 08/03/2021): Epoch 100/100 (100.00%) | T: 3.02847 V: 0.79508\n",
      "\n",
      "Test Period: 10/14/2013 - 10/16/2023 (10.01 years)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set random seed (torch) for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Initialize models dictionary\n",
    "models = {\n",
    "    \"FCN\": FCNPortOpt_NL,\n",
    "    \"CNN\": CNNPortOpt_NL,\n",
    "    \"LSTM\": LSTMPortOpt_NL,\n",
    "}\n",
    "\n",
    "# Initialize empty weights dictionary\n",
    "weights = {model: [] for model in models.keys()}\n",
    "\n",
    "# Define number of trading days per year and initialize TimeSeriesSplit\n",
    "days_in_year = 365\n",
    "trading_days = 252\n",
    "retrain_after = 2\n",
    "tss = TimeSeriesSplit(test_size=trading_days*retrain_after)\n",
    "val_size = .2 # 20% validation window\n",
    "\n",
    "# Loop over model\n",
    "for a, (name, model_) in enumerate(models.items()):\n",
    "    \n",
    "    print(f\"{a+1}: {name} ---\", end=\"\\n\")\n",
    "\n",
    "    # Vary input dimensions based on NN architecture\n",
    "    if name == \"CNN\": \n",
    "        X = X_.transpose(0, 2, 1)\n",
    "        input_size = X.shape[1]\n",
    "    if name == \"FCN\": \n",
    "        X = X_.reshape((X_.shape[0], -1))\n",
    "        input_size = X.shape[-1]\n",
    "    if name == \"LSTM\": \n",
    "        X = X_\n",
    "        input_size = X.shape[-1]\n",
    "\n",
    "    dates = features.index\n",
    "    test_start = None\n",
    "\n",
    "    # Walk forward model training and prediction    \n",
    "    for e, (train_idx, test_idx) in enumerate(tss.split(X)):\n",
    "        \n",
    "        train_start, train_end = strftime(dates[train_idx][0]), strftime(dates[train_idx][-1])\n",
    "        \n",
    "        if e == 0:\n",
    "            test_start = dates[test_idx][lookback+1]\n",
    "        \n",
    "        val_idx = int(len(train_idx) * (1 - val_size))\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_val, X_test = X[:val_idx], X[val_idx:], X[test_idx]\n",
    "        y_train, y_val, y_test = y[:val_idx], y[val_idx:], y[test_idx]\n",
    "\n",
    "        # Convert inputs and targets to PyTorch tensors\n",
    "        X_train, X_val, X_test, y_train, y_val, y_test = to_tensors(\n",
    "            X_train, X_val, X_test, y_train, y_val, y_test\n",
    "        )\n",
    "\n",
    "        # Hidden dimension and output dimension\n",
    "        hidden_size = 64                       # 64 neurons\n",
    "        output_size = y_train.shape[-1]        # 4 assets\n",
    "\n",
    "        # Initialize model and optimizer\n",
    "        model = model_(input_size, hidden_size, output_size)\n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "        # Define number of epochs\n",
    "        epochs = 100\n",
    "\n",
    "        # Construct training loop\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_train)\n",
    "            obj = neg_sharpe_ratio(outputs, y_train)\n",
    "            obj.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Evaluate validation performance\n",
    "            with torch.no_grad():\n",
    "                val_allocations = model(X_val)\n",
    "                val_obj = neg_sharpe_ratio(val_allocations, y_val)\n",
    "            \n",
    "            print(\n",
    "                f\"Split {e+1} ({train_start} - {train_end}):\",\n",
    "                f\"Epoch {epoch + 1}/{epochs} ({(epoch + 1)/epochs*100:,.2f}%)\",\n",
    "                \"|\",\n",
    "                f\"T: {-obj.item():,.5f}\", \n",
    "                f\"V: {-val_obj.item():,.5f}\" ,\n",
    "                end=\"\\r\"\n",
    "            )\n",
    "\n",
    "        print()\n",
    "        \n",
    "        # Get the outputs (asset allocations) after training\n",
    "        with torch.no_grad():\n",
    "            model_allocations = model(X_test)\n",
    "            weights[name].append(model_allocations)\n",
    "    \n",
    "    print()\n",
    "    print(f\"Test Period: {strftime(test_start)} - {strftime(dates[-1])}\", \n",
    "          f\"({(dates[-1] - test_start).days / days_in_year:,.2f} years)\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FCN</th>\n",
       "      <th>CNN</th>\n",
       "      <th>LSTM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-10-14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-15</th>\n",
       "      <td>-0.000468</td>\n",
       "      <td>0.149428</td>\n",
       "      <td>0.003144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-16</th>\n",
       "      <td>0.004297</td>\n",
       "      <td>-0.237855</td>\n",
       "      <td>-0.004907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-17</th>\n",
       "      <td>0.002793</td>\n",
       "      <td>-0.087320</td>\n",
       "      <td>0.000966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-18</th>\n",
       "      <td>0.001672</td>\n",
       "      <td>-0.033186</td>\n",
       "      <td>0.002700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 FCN       CNN      LSTM\n",
       "Date                                    \n",
       "2013-10-14  0.000000  0.000000  0.000000\n",
       "2013-10-15 -0.000468  0.149428  0.003144\n",
       "2013-10-16  0.004297 -0.237855 -0.004907\n",
       "2013-10-17  0.002793 -0.087320  0.000966\n",
       "2013-10-18  0.001672 -0.033186  0.002700"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Backtest optimized portfolios\n",
    "nn_unlev_rets = []\n",
    "weights_dfs = {model: None for model in models.keys()}\n",
    "\n",
    "# Set loan variables\n",
    "loan_term = 2     # 2Y repayment schedule\n",
    "loan_ir = 0.05    # 5% interest rate\n",
    "days_in_year = 365\n",
    "\n",
    "amrtzn = 1 / (days_in_year * loan_term)\n",
    "ir = loan_ir / days_in_year\n",
    "\n",
    "# Set transaction variables\n",
    "trnsc_cr = 0.002  # 0.2% transaction cost rate\n",
    "\n",
    "for name, weights_ in weights.items():\n",
    "    weights_concat = np.concatenate(weights_)\n",
    "    \n",
    "    # Reindex features to match weights\n",
    "    reindexed_features = features.iloc[-len(weights_concat):]\n",
    "    weights_df = pd.DataFrame(weights_concat, index=reindexed_features.index, columns=indices)\n",
    "\n",
    "    # Shift weights for real time information lag\n",
    "    weights_df = weights_df.shift().dropna()\n",
    "\n",
    "    reindexed_returns = reindexed_features[return_cols][1:]\n",
    "    reindexed_returns.columns = indices\n",
    "\n",
    "    # Portfolio returns = sum of (weights * returns)\n",
    "    returns = (weights_df * reindexed_returns).sum(axis=1)\n",
    "\n",
    "    # Account for transaction costs\n",
    "    c = weights_df.diff().abs().sum(axis=1)\n",
    "    tc = c * trnsc_cr\n",
    "    returns = returns - tc\n",
    "    \n",
    "    returns.name = name\n",
    "    nn_unlev_rets.append(returns)\n",
    "\n",
    "    weights_dfs[name] = weights_df\n",
    "\n",
    "nn_unlev_rets = pd.concat(nn_unlev_rets, axis=1)\n",
    "nn_unlev_rets.loc[nn_unlev_rets.index.min()] = 0\n",
    "\n",
    "nn_unlev_rets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_unlev_rets.to_csv(\"workflow/data/returns/nn_unlev_rets.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
