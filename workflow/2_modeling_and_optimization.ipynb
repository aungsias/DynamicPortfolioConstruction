{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "In this project, I've engineered an adaptive machine learning algorithm that undergoes biannual recalibration to select the most accurate model for sector-based investment strategies. To counteract the pitfalls of over-forecasting, the algorithm employs a custom loss function that penalizes overpredictions. It comprehensively integrates a diverse range of financial indicators, including equity, debt, commodities, and market volatility. To enhance computational efficiency and model precision, I employed Principal Component Analysis for feature reduction. The model's robustness was substantiated through a 15-year backtest, during which it outperformed the SPY index by an estimated 91.85%. The finalized, vetted model has been encapsulated in a real-time dashboard.\n",
    "\n",
    "## Business Understanding: Adaptive Sector Selection\n",
    "The mercurial landscape of the financial markets warrent strategies that are dynamic and adapative, but even strategies like sector rotation often fall short due to their reliance on static heuristics. This project mitigates such limitations by employing a machine learning-driven \"model of models\" framework. This ensemble of algorithms undergoes biannual retraining and evaluation. The best-performing model is then selected for the next six-month cycle, ensuring the investment strategy continually adapts to current market conditions.\n",
    "\n",
    "Once the leading model is identified, it selects the investment sector based on its predicted mean returns, specifically targeting the sector forecasted to yield the highest return. This dynamic, model-driven sector selection aims to optimize investment outcomes by leveraging timely and precise machine learning predictions.\n",
    "\n",
    "The strategy is then tested via a 15-year backtest, offering empirical validation of its sector-based approach. Thus, the framework's utility manifests in its ability to not only adapt to market vicissitudes but also pinpoint the most promising sectors for investment based on forecasts.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Modeling\n",
    "This notebook goes through the process of modeling:\n",
    "1. [Custom Error Function: Over-Under Error](#custom-error-function-over-under-error)\n",
    "2. [The Nature of Walk Forward Cross-Validation and Training](#the-nature-of-walk-forward-cross-validation-and-training)\n",
    "3. [\"Model of Models\" Architecture](#model-of-models-architecture)\n",
    "4. [Modeling](#modeling)\n",
    "    - [The Use of PCA](#the-use-of-pca)\n",
    "    - [Naive Model](#naive-model)\n",
    "    - [`ARIMAX` Model](#arimax-model)\n",
    "    - [`sklearn` Models](#sk)\n",
    "\n",
    "The below are the necessary imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Custom modules and functions\n",
    "from capstone.model_selection import (\n",
    "    overunder_error, \n",
    "    naive_cross_val_score, \n",
    "    arimax_cross_val_score\n",
    ")\n",
    "\n",
    "from capstone.utils import read_file, get_sectors, set_plot_style\n",
    "\n",
    "# SARIMAX model from statsmodels\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# sklearn models\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Progres bar for loops\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Ignore warnings\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")\n",
    "\n",
    "set_plot_style()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Error Function: Over-Under Error\n",
    "\n",
    "The Over-Under Error (OUE) calculates a loss based on the differences between true and predicted portfolio values. It is given by the formula:\n",
    "\n",
    "$$\\text{loss} = \n",
    "\\begin{cases} \n",
    "\\text{underpred penalty} \\times \\left| \\text{residual} \\right|^\\alpha & \\text{if residual} < 0 \\\\\n",
    "\\text{overpred penalty} \\times \\left| \\text{residual} \\right|^\\alpha & \\text{otherwise}\n",
    "\\end{cases}$$\n",
    "\n",
    "Read below for the documentation or visit the [`capstone.model_selection`](capstone/model_selection.py) module for the source code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function overunder_error in module capstone.model_selection:\n",
      "\n",
      "overunder_error(y_true, y_pred, underpred_penalty=1.0, overpred_penalty=1.0, alpha=0.5)\n",
      "    Calculate the Over-Under Error for portfolio optimization.\n",
      "    \n",
      "    Parameters:\n",
      "        y_true (array-like): True portfolio values.\n",
      "        y_pred (array-like): Predicted portfolio values.\n",
      "        underpred_penalty (float, optional): Penalty factor for underpredictions. Default is 1.0.\n",
      "        overpred_penalty (float, optional): Penalty factor for overpredictions. Default is 1.0.\n",
      "        alpha (float, optional): Exponent for residual calculation. Default is 0.5.\n",
      "    \n",
      "    Returns:\n",
      "        float: Mean Over-Under Error.\n",
      "    \n",
      "    The Over-Under Error is a custom loss function written for portfolio optimization. It calculates a loss based on the \n",
      "    differences between true and predicted portfolio values. The function allows for penalties on overpredictions and \n",
      "    underpredictions using the 'overpred_penalty' and 'underpred_penalty' parameters, respectively. The 'alpha' parameter\n",
      "    determines the exponent for the residual calculation.\n",
      "    \n",
      "    If the residual (y_true - y_pred) is negative, it represents an underprediction, and the underprediction penalty is\n",
      "    applied. If the residual is positive, it represents an overprediction, and the overprediction penalty is applied.\n",
      "    \n",
      "    The function returns the mean Over-Under Error, which can be used as an optimization objective in portfolio management.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(overunder_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though the function allows parametization of the overprediction penalty (`overpred_penalty`) and underprediction penalty (`underpred_penalty`), for the purposes of a long-only portfolio I've set `underpred_penalty = 0` and `overpred_penalty = 2`. This reflects a specific calculus, namely:\n",
    "\n",
    "1. **Underprediction Tolerance**: In a long-only portfolio, underpredicting an asset's performance isn't inherently detrimental. If an asset outperforms your model's predictions, the consequence is a positive surprise. Hence, `underpred_penalty = 0`.\n",
    "2. **Overprediction Risk**: Overestimating an asset's performance, however, can be more damaging in a long-only strategy. It may lead to an allocation that is disproportionately heavy in underperforming assets. This can hamper the portfolio's overall returns and increase its risk profile. Therefore, `overpred_penalty = 2` provides a stringent control mechanism for overoptimistic forecasts.\n",
    "3. **Risk Aversion**: The higher overprediction penalty factor acts as a risk management tool, pushing the model toward conservative estimates and mitigating the impact of potential overallocations.\n",
    "4. **Resource Allocation**: Penalizing overprediction guides the model to allocate resources more judiciously, reinforcing positions in assets that have a more reliable performance outlook.\n",
    "\n",
    "That said, whether overpredicting or underpredicting is detrimental to the strategy is still contingent on one's specific risk tolerance, so feel free to play around with the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Nature of Walk Forward Cross-Validation and Training\n",
    "\n",
    "Walk Forward Cross-Validation (WFCV) is a form of time-series cross-validation that simulates a realistic trading environment. Unlike traditional cross-validation methods which randomly partition data, walk-forward cross validation (WFCV) respects the temporal order of observations.\n",
    "\n",
    "![Walk-Forward Cross Validation](img/wfcv.png)\n",
    "\n",
    "WFCV can be \"rolling\" or \"expanding\". The picture above shows an expanding approach, where each testing window gets added to the subsequent training window; the training window thus \"expands\". In a rolling approach, the training window \"rolls\" forward, maintaining a fixed size. As new data points become available for testing, the earliest data points in the training set are removed to keep its size constant.\n",
    "\n",
    "In this project I use the expanding approach, as the validation slice per time frame is small (126 days). The algorithm thus needs as much data as it can get from each time frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Model of Models\" Architecture\n",
    "\n",
    "The framework in this project employs a dynamic \"Model of Models\" architecture that re-trains each constituent model biannually, using data from the preceding six months. The model yielding the best Over-Under Error (OUE) score is selected as the lead model for the subsequent period. This chosen model identifies the most promising sector for investment based on the mean of its predicted returns. Stocks from the chosen sector are identified via their GICS segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get to modeling, we'll need to load in `master_df.csv` from `data`, after which we'll separate it out into it features and targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4230, 109), (4230, 11))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in files\n",
    "sectors = get_sectors()\n",
    "df = read_file(\"master_df\", index_col=0)\n",
    "\n",
    "# Separate `df` into features and targets\n",
    "y_all = df[sectors]\n",
    "X = df[df.columns[~df.columns.isin(sectors)]]\n",
    "\n",
    "X.shape, y_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Model\n",
    "\n",
    "We'll start with our naive model. This model uses the past 6 months of returns *as* the forecasted returns and will serve as a baseline upon which we can assess the efficacy of the more sophisticated models. Below is how I cross-validation function for the naive model. Visit the [`capstone.model_selection`](capstone/model_selection.py) module to see source code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function naive_cross_val_score in module capstone.model_selection:\n",
      "\n",
      "naive_cross_val_score(r_true: pandas.core.series.Series, r_hat: pandas.core.series.Series, cv: int, scorer: Callable, **scorer_kwargs: Optional[Any]) -> List[float]\n",
      "    Perform time-series cross-validation using a naive forecast model.\n",
      "    \n",
      "    Parameters:\n",
      "        - r_true (Series): Actual target values.\n",
      "        - r_hat (Series): Predicted target values.\n",
      "        - cv (int): Number of splits/folds for time-series cross-validation.\n",
      "        - scorer (Callable): Scoring function to evaluate the predictions. \n",
      "                             Must take two arrays 'y_true' and 'y_pred' as arguments,\n",
      "                             along with any additional keyword arguments (**scorer_kwargs).\n",
      "        - **scorer_kwargs (Optional[Any]): Additional keyword arguments to pass to the scoring function.\n",
      "    \n",
      "    Returns:\n",
      "        - cv_scores (List[float]): List of scores calculated for each fold during cross-validation.\n",
      "    \n",
      "    This function performs time-series cross-validation on a naive forecast model. It employs a user-defined\n",
      "    scoring function to evaluate the model's predictions. The scoring function can be customized through additional\n",
      "    keyword arguments, allowing for flexible evaluation metrics.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(naive_cross_val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the forecast horizon in terms of trading days per year\n",
    "trading_days = 252\n",
    "forecast = int(trading_days / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the forecast horizon in terms of trading days per year\n",
    "trading_days = 252\n",
    "forecast = int(trading_days / 2)\n",
    "\n",
    "# Shift returns for forecasting, align indices\n",
    "returns_shifted = y_all.shift(forecast).dropna()\n",
    "returns_reind = y_all.reindex(returns_shifted.index)\n",
    "\n",
    "# Initialize output DataFrames\n",
    "naive_oues = pd.DataFrame()\n",
    "naive_preds = pd.DataFrame()\n",
    "\n",
    "# Loop through sectors\n",
    "for sector in sectors:\n",
    "    r_trues = returns_reind[sector]\n",
    "    r_hats = returns_shifted[sector]\n",
    "    \n",
    "    # Time-chunk loop\n",
    "    for i in range(forecast + 1, len(returns_reind), forecast):\n",
    "        r_hat = r_hats.iloc[i-forecast:i]\n",
    "        r_true = r_trues.iloc[i-forecast:i]\n",
    "        \n",
    "        # Calculate and store mean over-under loss\n",
    "        mean_oul = np.mean(\n",
    "            naive_cross_val_score(\n",
    "                r_true, r_hat, cv=2, scorer=overunder_error,\n",
    "                overpred_penalty=2, underpred_penalty=0\n",
    "            )\n",
    "        )\n",
    "\n",
    "        naive_oues.loc[r_hat.index.max(), sector] = mean_oul\n",
    "        naive_preds.loc[r_hat.index.max(), sector] = np.mean(r_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Naive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-05-27</th>\n",
       "      <td>0.112676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-24</th>\n",
       "      <td>0.089535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-26</th>\n",
       "      <td>0.114220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-25</th>\n",
       "      <td>0.126298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-30</th>\n",
       "      <td>0.114692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Naive\n",
       "2021-05-27  0.112676\n",
       "2021-11-24  0.089535\n",
       "2022-05-26  0.114220\n",
       "2022-11-25  0.126298\n",
       "2023-05-30  0.114692"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take the mean Over-Under Error (OUE) across sectors\n",
    "mean_naive_oues = pd.DataFrame(naive_oues.mean(axis=1), columns=[\"Naive\"])\n",
    "mean_naive_oues.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Naive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-05-27</th>\n",
       "      <td>MATERIALS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-24</th>\n",
       "      <td>ENERGY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-26</th>\n",
       "      <td>ENERGY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-25</th>\n",
       "      <td>ENERGY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-30</th>\n",
       "      <td>INDUSTRIALS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Naive\n",
       "2021-05-27    MATERIALS\n",
       "2021-11-24       ENERGY\n",
       "2022-05-26       ENERGY\n",
       "2022-11-25       ENERGY\n",
       "2023-05-30  INDUSTRIALS"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take the sector with the highest predicted mean return\n",
    "naive_sectors = pd.DataFrame(naive_preds.idxmax(axis=1), columns=[\"Naive\"])\n",
    "naive_sectors.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ARIMAX Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a baseline to compare to, we'll begin with our ARIMAX model. ARIMA (AutoRegressive Integrated Moving Average) is a time-series forecasting model that uses past observations and their lags to predict future points. ARIMAX extends ARIMA by incorporating external (X) variables, allowing the model to capture additional influencing factors not present in the time-series itself. Learn more about ARIMAX [here](https://www.smarten.com/blog/arimax-forecasting-enterprise-analysis/#:~:text=An%20Autoregressive%20Integrated%20Moving%20Average,moving%20average%20(MA)%20terms.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3600c9749ea841caa85514fbf68eba92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Shift the features to match the forecast horizon, and drop any missing values\n",
    "X_shifted = X.shift(forecast).dropna()\n",
    "\n",
    "# Create a pipeline for standardizing and applying PCA\n",
    "pca_pipe = make_pipeline(StandardScaler(), PCA(n_components=.8, random_state=42))\n",
    "\n",
    "# Define the ARIMAX orders for ARIMA and seasonal components\n",
    "order = (1, 0, 1) # Returns are usually stationary, so no differencing applied\n",
    "\n",
    "# Initialize empty DataFrames to store predictions and over-under loss scores\n",
    "arimax_preds = pd.DataFrame()\n",
    "arimax_ouls = pd.DataFrame()\n",
    "\n",
    "# Loop through each sector\n",
    "for sector in tqdm(sectors):\n",
    "\n",
    "    # Extract the target variable for the current sector\n",
    "    y = y_all[sector].reindex(X_shifted.index)\n",
    "\n",
    "    # Loop through the data with a window equal to the forecast horizon\n",
    "    for i in range(forecast, len(y), forecast):\n",
    "        \n",
    "        # Split the data into training and testing sets\n",
    "        X_train, X_test = X_shifted.iloc[i-forecast:i], X_shifted.iloc[i:i+forecast]\n",
    "        y_train, y_test = y[i-forecast:i], y[i:i+forecast]\n",
    "\n",
    "        # Apply PCA to the training and testing feature sets\n",
    "        X_train_pca = pca_pipe.fit_transform(X_train)\n",
    "        X_test_pca = pca_pipe.transform(X_test)\n",
    "\n",
    "        # Perform time-series cross-validation and calculate the mean over-under loss\n",
    "        mean_oul = np.mean(\n",
    "            arimax_cross_val_score(\n",
    "                X_train,\n",
    "                y_train,\n",
    "                order=order,\n",
    "                pca=pca_pipe,\n",
    "                cv=2,\n",
    "                scorer=overunder_error,\n",
    "                overpred_penalty=2,\n",
    "                underpred_penalty=0\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Store the mean over-under loss score\n",
    "        arimax_ouls.loc[X_test.index.min(), sector] = mean_oul\n",
    "\n",
    "        # Fit the ARIMAX model to the training data\n",
    "        model = SARIMAX(y_train.values, X_train_pca, order=order).fit()\n",
    "\n",
    "        # Generate forecasts for the testing data\n",
    "        forecast_results = model.get_forecast(steps=len(X_test_pca), exog=X_test_pca)\n",
    "        y_hat = forecast_results.predicted_mean\n",
    "\n",
    "        # Store the mean forecasted value\n",
    "        arimax_preds.loc[X_test.index.min(), sector] = np.mean(y_hat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
